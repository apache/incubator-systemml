#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# This file provides a number of numerical solvers for systems of linear equations
# All of these solvers have the same function signature:
# Given a system of linear eqations of size m:
# R is a m times m Matrix
# b is a m times 1 Matrix (m sizes vector)
# the sys of lin eq. to be solved is defined by:
# R * x = b
# with the unknown variables x being contained by an m times 1 matrix

# Function Parameters:
# Required:
# R Matrix
# b Matrix
# Optional:
# tolerance -> early escape of solver if difference of normed result of previous iteration and current iteration is smaller than the tolerance
# max_iterations -> maximal number of iterations

# Returns:
# Double Matrix with the approximated values of the unknown variables


# Conjugate gradients solver for Systems of Linear Equations
# TODO: test correctness
cg = function (Matrix[Double] R, Matrix[Double] b, Double tolerance = 0.01, Integer max_iterations = 1000) return (Matrix[Double] y_hat){
	y_hat = matrix(0, nrow(R), 1)
	iter = 0

	A = R #+ diag(matrix(1, rows=nrow(R), cols=1))
	Z = t(A)%*%A
	r = -(t(A)%*%b)
	p = -r
	norm_r2 = sum(r^2)
	
	continue = (norm_r2 != 0)
	
	while(iter < max_iterations & continue){
		q = Z%*%p
		alpha = norm_r2 / as.scalar(t(p) %*% q)
		y_hat += alpha * p
		r += alpha * q
		old_norm_r2 = norm_r2
		norm_r2 = sum(r^2)
		continue = (norm_r2 >= tolerance)
		beta = norm_r2 / old_norm_r2
		p = -r + beta * p
		iter += 1
	}
}

# Jacobi solver for Systems of Linear Equations
jacobi = function (Matrix[Double] R, Matrix[Double] b, Double tolerance = 0.01, Integer max_iterations = 1000)  return (Matrix[Double] x){
	
	x = matrix(0, nrow(R), 1)
  	iter = 0
	diff = tolerance+1
	
	#checking for strict diagonal dominance
	#required for jacobi's method
  	check = sum(rowSums(abs(R)) >= 1)
	if(check > 0){
		print("WARNING: The matrix is not diagonal dominant. Suggest switching to an exact solver.")
	}
		
	while(iter < max_iterations & diff > tolerance){
		new_weights = b - R%*%x
		diff = sum((new_weights-x)^2)
		x = new_weights
		iter += 1
	}
}