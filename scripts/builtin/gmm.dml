#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# ------------------------------------------
# Guassian Mixture Model
# ------------------------------------------

# INPUT PARAMETERS:
# ---------------------------------------------------------------------------------------------
# NAME            TYPE    DEFAULT     MEANING
# ---------------------------------------------------------------------------------------------
# X               Double   ---       Matrix X  
# components      Integer  3         Number of components in the Gaussian mixture model
# iterations      Integer  10        number of iterations
# model           String   "V"       Univariate mixture     "V": unequal variance
#                                                           "E": equal variance
#                                    Multivariate mixture  "VVI": spherical, unequal volume 
#                                                          "EEI": spherical, equal volume
# eps            Double    0.000001  value for convergence 
# ---------------------------------------------------------------------------------------------


#Output(s)
# ---------------------------------------------------------------------------------------------
# NAME            TYPE    DEFAULT     MEANING
# ---------------------------------------------------------------------------------------------
# weight          Double   ---       A matrix whose [i,k]th entry is the probability that observation i in the test data belongs to the kth class




m_gmm = function(Matrix[Double] X, Integer components = 3, Integer iter = 10, String model = "V", Double eps = 0.000001, Boolean verbose = FALSE )
return (Matrix[Double] weights)
{
  # Determine the initial GMM paramters from Kmeans
  # μ, σ, weights and phi
  
  phi = matrix(1/components, 1, components)
  weights = matrix(1/components, nrow(X), components)
  
  [C, Y] = kmeans(X,  components, 10, 10, eps, FALSE, 25)
  mu = C
  sigma = list()
  
  for(i in 1:components)
    sigma = append(sigma, covMatrix(X, matrix(1, nrow(X), 1)) ) #diag(matrix(1, ncol(X), 1))

  loglikPre = sum(log(rowSums(weights*phi)))
  loglikDiff = 1
  i = 1
  bic = matrix(0, iter, 1)
  df = (ncol(X)*ncol(X) - ncol(X))/2 + (2*ncol(X) + 1)
  df = components * df -1
  print("df "+df)
  while(i <= iter & loglikDiff >= eps ){
    print("iteration ----------------------------------"+i)
     # 
    # Estimation Step
    [weights, loglikNew] = predict_prob(X, components, mu, sigma, phi)
    phi = colMeans(weights)
    print("phi "+toString(phi))
    # Maximization Step - Update parameter
  
    for(j in 1:components)
    {
      wk = weights[, j]
      sum_wk = sum(wk)
      mu[j, ] = colSums(X*wk)/sum_wk
      sigma[j] = covMatrix(X, (wk/sum_wk)) # A covariance matrix instead of single covariance value
      print("mu m "+toString(mu[j, ]))
      print("sigma m "+toString(as.matrix(sigma[j])))
    }
    loglikDiff = abs(loglikNew - loglikPre)
    bic[i,1] = -2 * loglikNew + df * log(nrow(X))
    i = i+1
  }
  
  # predict 
  predict = rowIndexMax(weights)
  if(verbose) {
    print("logliklihood diff "+loglikDiff)
    print("logliklihood "+loglikNew)
    print("BIC for each iteration "+toString(bic))
    print("predictions \n"+toString(predict))
    print("weights \n"+toString(weights))
  }

}

covMatrix = function(Matrix[Double] X, Matrix[Double] w)
return (Matrix[Double] covM) 
{ 
  covM = matrix(0, ncol(X), ncol(X))
  if(ncol(X) < 2 )
    covM[1,1] = var(X)

  wmu = colSums(X*w)/sum(w)
  Xc = X - wmu
  # R = (t(Xc) %*% Xc)/(nrow(X)-1)/ (t(colSds(X)) %*% colSds(X)); #cov(X)
  # print("this is wsigma "+toString(R));
  sig = 1/(sum(w)) * (t(Xc * w) %*% Xc) 
    
  covM = sig  
  # print("this is wsigma "+toString(sig))
  # for(i in 1:ncol(X))
    # for(j in 1:ncol(X))
      # covM[i, j] = cov(X[,i], X[,j], w)
}

predict_prob = function(Matrix[Double] X, Integer components, Matrix[Double] mu, List[Unknown] sigma, Matrix[Double] phi)
  return (Matrix[Double] weights, Double loglik)
{
  likelihood = matrix(0, nrow(X), components )
  for(i in 1:components)
  {

    likelihood[, i] = mvpdf(X, mu[i,], as.matrix(sigma[i]))
  }
  numer = likelihood * phi
  denom = rowSums(numer)
  loglik = sum(log(denom)) 
 
  weights = numer/denom

}

mvpdf = function(Matrix[Double] X, Matrix[Double] mu, Matrix[Double] sigma) 
return (Matrix[Double] pdf)
{
  pdf = matrix(0, nrow(X), 1)
  # [eva, evec] = eigen(sigma)
  # det = colProds(eva)
  # det = as.scalar(det)
  # print("this is eval "+det)
  det = determinant(sigma, nrow(sigma))
    print("det "+det)
  if (det == 0) {
    stop("Determinant is equal to 0.")
  }
  d = ncol(X)
  for(i in 1:nrow(X))
  {
    x_m = X[i, ] - mu 
    p1 = 1/sqrt((2*pi)^d*det) 
    p2 = -0.5 * x_m %*% inverse(sigma) %*% t(x_m)
    p3 = p1 * exp(p2)
    pdf[i,1] += as.scalar(p1 * exp(p2))
  }
  # print("pdf "+toString(pdf))
}

determinant = function(Matrix[Double] X, Double n)
  return (Double det)
{      
 
  # temporary array for storing row  
  # int []temp = new int[n + 1];  
  num1=0; num2=0; detr = 1;index=0;total = 1;
  temp = matrix(0, n+1, 1)        
  # loop for traversing the diagonal elements  
  for(i in 1:n)  
  {  
    index = i; # initialize the index  
              
    # finding the index which has non zero value  
    while(as.scalar(X[index, i]) == 0 & index < n) 
    {  
      index =  index + 1;      
                  
    }  
    if(index == n)# if there is non zero element  
    {  
    # the determinat of matrix as zero  
                  
    }  
    if(index != i)  
    {  
      # loop for swaping the diagonal element row and index row  
      for(j in 1:n)  
      {  
        swap(X, index, j, i, j); 
        print("after swap "+toString(X))
      }  
      # determinant sign changes when we shift rows  
      # go through determinant properties  
        detr = as.integer(detr* (-1)^(index-i));  
    }  
          
    # storing the values of diagonal row elements  
    for(j in 1:n)  
    {  
      temp[j,1] = X[i,j];  
                  
    }  
      
    # traversing every row below the diagonal element 
    j = i+1
    while(j<=n)  
    {  
      num1 = as.scalar(temp[i,1]);  # value of diagonal element  
      num2 = as.scalar(X[j, i]); # value of next row element  
                  
      # traversing every column of row  
      # and multiplying to every row  
      for(k in 1:n)  
      {  
                  
        # multiplying to make the diagonal  
        # element and next row element equal  
        X[j, k] = (num1 * X[j, k]) - (num2 * temp[k, 1]);  
                      
      }  
      total = total * num1; # Det(kA)=kDet(A);
      j = j+1
    }  
              
  }  
      
    # mulitplying the diagonal elements to get determinant  
  for(i in 1:n)  
  {  
    detr = detr * as.scalar(X[i, i]);  
              
  }  
  det = (detr/total); # Det(kA)/k=Det(A);  
} 
 
  
swap =  function(Matrix[Double] X, Integer i1, Integer j1, Integer i2, Integer j2) 
  # return (Matrix[Double] X1)
{ 
  print("before swap "+toString(X))
  temp = as.scalar(X[i1, j1])
    # int temp = arr[i1][j1];
  X[i1, j1] = as.scalar(X[i2, j2]); 
  X[i1, j1] = as.scalar(X[i2, j2])
  X[i2, j2] = temp; 
  # X1 = X
}