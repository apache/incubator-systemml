{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SystemDS on Colaboratory.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX60cA7YuZsw",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright &copy; 2020 The Apache Software Foundation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GEGDZ9GuZGp",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "# @title Apache Version 2.0 (The \"License\");\n",
        "#-------------------------------------------------------------\n",
        "#\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements.  See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership.  The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License.  You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied.  See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License.\n",
        "#\n",
        "#-------------------------------------------------------------"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbCdLjRoy2A",
        "colab_type": "text"
      },
      "source": [
        "### Developer notebook for Apache SystemDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhdfvxkEq1BX",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"\"><table class=\"\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/apache/systemds/blob/master/notebooks/systemds_dev.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" width= \"32px\">Run in Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/apache/systemds/blob/master/notebooks/systemds_dev.ipynb\">\n",
        "<img width=32px src=\"https://github.githubassets.com/images/modules/open_graph/github-mark.png\">View source on GitHub</a></td>\n",
        "</table></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efFVuggts1hr",
        "colab_type": "text"
      },
      "source": [
        "This Jupyter/Colab-based tutorial will interactively walk through development setup and running SystemDS in both the\n",
        "\n",
        "A. standalone mode \\\n",
        "B. with Apache Spark.\n",
        "\n",
        "Flow of the notebook:\n",
        "1. Download and Install the dependencies\n",
        "2. Go to section **A** or **B**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBC5JPhkGbIV",
        "colab_type": "text"
      },
      "source": [
        "#### Download and Install the dependencies\n",
        "\n",
        "1. **Runtime:** Java (OpenJDK 8 is preferred)\n",
        "2. **Build:** Apache Maven\n",
        "3. **Backend:** Apache Spark (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkLasseNylPO",
        "colab_type": "text"
      },
      "source": [
        "##### Setup\n",
        "\n",
        "A custom function to run OS commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wmf-7jfydVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run and print a shell command.\n",
        "def run(command):\n",
        "  print('>> {}'.format(command))\n",
        "  !{command}\n",
        "  print('')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvD4HBMi0ohY",
        "colab_type": "text"
      },
      "source": [
        "##### Install Java\n",
        "Let us install OpenJDK 8. More about [OpenJDK ↗](https://openjdk.java.net/install/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xnb_ePUyQIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "edc9c833-c62d-42d6-c171-3167d0fd7481"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# run the below command to replace the existing installation\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "!java -version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhmBWf3u3Q0o",
        "colab_type": "text"
      },
      "source": [
        "##### Install Apache Maven\n",
        "\n",
        "SystemDS uses Apache Maven to build and manage the project. More about [Apache Maven ↗](http://maven.apache.org/).\n",
        "\n",
        "Maven builds SystemDS using its project object model (POM) and a set of plugins. One would find `pom.xml` find the codebase!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I81zPDcblchL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c859e0a-dba9-49f3-df25-5d3dbe9f0d48"
      },
      "source": [
        "# Download the maven source.\n",
        "maven_version = 'apache-maven-3.6.3'\n",
        "maven_path = f\"/opt/{maven_version}\"\n",
        "\n",
        "if not os.path.exists(maven_path):\n",
        "  run(f\"wget -q -nc -O apache-maven.zip https://downloads.apache.org/maven/maven-3/3.6.3/binaries/{maven_version}-bin.zip\")\n",
        "  run('unzip -q -d /opt apache-maven.zip')\n",
        "  run('rm -f apache-maven.zip')\n",
        "\n",
        "# Let's choose the absolute path instead of $PATH environment variable.\n",
        "def maven(args):\n",
        "  run(f\"{maven_path}/bin/mvn {args}\")\n",
        "\n",
        "maven('-v')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> wget -q -nc -O apache-maven.zip https://downloads.apache.org/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.zip\n",
            "\n",
            ">> unzip -q -d /opt apache-maven.zip\n",
            "\n",
            ">> rm -f apache-maven.zip\n",
            "\n",
            ">> /opt/apache-maven-3.6.3/bin/mvn -v\n",
            "\u001b[1mApache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)\u001b[m\n",
            "Maven home: /opt/apache-maven-3.6.3\n",
            "Java version: 1.8.0_252, vendor: Private Build, runtime: /usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "Default locale: en_US, platform encoding: UTF-8\n",
            "OS name: \"linux\", version: \"4.19.104+\", arch: \"amd64\", family: \"unix\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xphbe3R43XLw",
        "colab_type": "text"
      },
      "source": [
        "##### Install Apache Spark (Optional, if you want to work with spark backend)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WgEa00pTs3w",
        "colab_type": "text"
      },
      "source": [
        "NOTE: If spark is not downloaded. Let us make sure the version we are trying to download is officially supported at\n",
        "https://spark.apache.org/downloads.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zdtkFkLnskx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b5b7b61c-a0cb-41bd-b800-3f4a5db65e52"
      },
      "source": [
        "# Spark and Hadoop version\n",
        "spark_version = 'spark-2.4.6'\n",
        "hadoop_version = 'hadoop2.7'\n",
        "spark_path = f\"/opt/{spark_version}-bin-{hadoop_version}\"\n",
        "if not os.path.exists(spark_path):\n",
        "  run(f\"wget -q -nc -O apache-spark.tgz https://downloads.apache.org/spark/{spark_version}/{spark_version}-bin-{hadoop_version}.tgz\")\n",
        "  run('tar zxf apache-spark.tgz -C /opt')\n",
        "  run('rm -f apache-spark.tgz')\n",
        "\n",
        "os.environ[\"SPARK_HOME\"] = spark_path\n",
        "os.environ[\"PATH\"] += \":$SPARK_HOME/bin\"\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> wget -q -nc -O apache-spark.tgz https://downloads.apache.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
            "\n",
            ">> tar zxf apache-spark.tgz -C /opt\n",
            "\n",
            ">> rm -f apache-spark.tgz\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91pJ5U8k3cjk",
        "colab_type": "text"
      },
      "source": [
        "#### Get Apache SystemDS\n",
        "\n",
        "Apache SystemDS development happens on GitHub at [apache/systemds ↗](https://github.com/apache/systemds)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPIprmg3lKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "293beeb7-bd1f-423f-fc3e-41414e0680eb"
      },
      "source": [
        "!git clone https://github.com/apache/systemds systemds --depth=1\n",
        "%cd systemds"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'systemds'...\n",
            "remote: Enumerating objects: 7557, done.\u001b[K\n",
            "remote: Counting objects: 100% (7557/7557), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4456/4456), done.\u001b[K\n",
            "remote: Total 7557 (delta 5559), reused 3710 (delta 3016), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7557/7557), 14.73 MiB | 9.80 MiB/s, done.\n",
            "Resolving deltas: 100% (5559/5559), done.\n",
            "/content/systemds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Fo9tPUzbWK",
        "colab_type": "text"
      },
      "source": [
        "##### Build the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Iorb0ICgHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cfa91d57-680d-42a4-d206-5e7e81b2102a"
      },
      "source": [
        "# Logging flags: -q only for ERROR; -X for DEBUG; -e for ERROR\n",
        "# Option 1: Build only the java codebase\n",
        "maven('clean package -q')\n",
        "\n",
        "# Option 2: For building along with python distribution\n",
        "# maven('clean package -P distribution')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> /opt/apache-maven-3.6.3/bin/mvn clean package -q\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUGac5w9ZRBQ",
        "colab_type": "text"
      },
      "source": [
        "### A. Working with SystemDS in **standalone** mode\n",
        "\n",
        "NOTE: Pay attention to *directories* and *relative paths*. :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5Nk2Bb4UU2O",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Set SystemDS environment variables\n",
        "\n",
        "These are useful for the `./bin/systemds` script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZnSzkq8UT32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export SYSTEMDS_ROOT=$(pwd)\n",
        "!export PATH=$SYSTEMDS_ROOT/bin:$PATH"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcxkh8cdUy1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo 'export SYSTEMDS_ROOT='$(pwd) >> ~/.bashrc\n",
        "!echo 'export PATH=$SYSTEMDS_ROOT/bin:$PATH' >> ~/.bashrc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyLmFCv6ZYk5",
        "colab_type": "text"
      },
      "source": [
        "##### 2. Download Haberman data\n",
        "\n",
        "Data source: https://archive.ics.uci.edu/ml/datasets/Haberman's+Survival\n",
        "\n",
        "About: The survival of patients who had undergone surgery for breast cancer.\n",
        "\n",
        "Data Attributes:\n",
        "1. Age of patient at time of operation (numerical)\n",
        "2. Patient's year of operation (year - 1900, numerical)\n",
        "3. Number of positive axillary nodes detected (numerical)\n",
        "4. Survival status (class attribute)\n",
        "    - 1 = the patient survived 5 years or longer\n",
        "    - 2 = the patient died within 5 year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrQFBQehV8SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ../data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ZFCTFmXFY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "aafc7c8c-b696-4fce-83d3-af8bef08b070"
      },
      "source": [
        "!wget -P ../data/ http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 18:44:02--  http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3103 (3.0K) [application/x-httpd-php]\n",
            "Saving to: ‘../data/haberman.data’\n",
            "\n",
            "\rhaberman.data         0%[                    ]       0  --.-KB/s               \rhaberman.data       100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-24 18:44:02 (348 MB/s) - ‘../data/haberman.data’ saved [3103/3103]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTo8Py_vOGpX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "9548a347-8537-4589-ca0e-f0721cd88454"
      },
      "source": [
        "# Display first 10 lines of the dataset\n",
        "# Notice that the test is plain csv with no headers!\n",
        "!sed -n 1,10p ../data/haberman.data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30,64,1,1\n",
            "30,62,3,1\n",
            "30,65,0,1\n",
            "31,59,2,1\n",
            "31,65,4,1\n",
            "33,58,10,1\n",
            "33,60,0,1\n",
            "34,59,0,2\n",
            "34,66,9,2\n",
            "34,58,30,1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy2kgVdkaeWK",
        "colab_type": "text"
      },
      "source": [
        "##### 2.1 Set `metadata` for the data\n",
        "\n",
        "The data does not have any info on the value types. So, `metadata` for the data\n",
        "helps know the size and format for the matrix data as `.mtd` file with the same\n",
        "name and location as `.data` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfypIgJWXT6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate metadata file for the dataset\n",
        "!echo '{\"rows\": 306, \"cols\": 4, \"format\": \"csv\"}' > ../data/haberman.data.mtd\n",
        "\n",
        "# generate type description for the data\n",
        "!echo '1,1,1,2' > ../data/types.csv\n",
        "!echo '{\"rows\": 1, \"cols\": 4, \"format\": \"csv\"}' > ../data/types.csv.mtd"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vis3V31bA53",
        "colab_type": "text"
      },
      "source": [
        "##### 3. Find the algorithm to run with `systemds`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0KosFhbhun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "634d02bd-ad86-43b3-fec5-f3aec18cc113"
      },
      "source": [
        "# Inspect the directory structure of systemds code base\n",
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin   CONTRIBUTING.md  docker  LICENSE\tpom.xml    scripts  target\n",
            "conf  dev\t       docs    NOTICE\tREADME.md  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7C5DVM7YfTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "ce54ecf5-ad7d-4718-bd4c-46f4d191eb91"
      },
      "source": [
        "# List all the scripts (also called top level algorithms!)\n",
        "!ls scripts/algorithms"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ALS-CG.dml\t\t   GLM.dml\t       naive-bayes.dml\n",
            "ALS-DS.dml\t\t   GLM-predict.dml     naive-bayes-predict.dml\n",
            "ALS_predict.dml\t\t   KM.dml\t       obsolete\n",
            "ALS_topk_predict.dml\t   Kmeans.dml\t       PCA.dml\n",
            "apply-transform.dml\t   Kmeans-predict.dml  random-forest.dml\n",
            "bivar-stats.dml\t\t   l2-svm.dml\t       random-forest-predict.dml\n",
            "Cox.dml\t\t\t   l2-svm-predict.dml  StepGLM.dml\n",
            "Cox-predict.dml\t\t   LinearRegCG.dml     StepLinearRegDS.dml\n",
            "CsplineCG.dml\t\t   LinearRegDS.dml     stratstats.dml\n",
            "CsplineDS.dml\t\t   m-svm.dml\t       transform.dml\n",
            "decision-tree.dml\t   m-svm-predict.dml   Univar-Stats.dml\n",
            "decision-tree-predict.dml  MultiLogReg.dml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PrxwviWJhNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b131f8de-9abc-4219-9400-2b3e8c4fdef2"
      },
      "source": [
        "# Output the algorithm documentation\n",
        "# start from line no. 22 onwards. Till 35th line the command looks like\n",
        "!sed -n 22,35p ./scripts/algorithms/Univar-Stats.dml"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#\n",
            "# DML Script to compute univariate statistics for all attributes in a given data set\n",
            "#\n",
            "# INPUT PARAMETERS:\n",
            "# -------------------------------------------------------------------------------------------------\n",
            "# NAME           TYPE     DEFAULT  MEANING\n",
            "# -------------------------------------------------------------------------------------------------\n",
            "# X              String   ---      Location of INPUT data matrix\n",
            "# TYPES          String   ---      Location of INPUT matrix that lists the types of the features:\n",
            "#                                     1 for scale, 2 for nominal, 3 for ordinal\n",
            "# CONSOLE_OUTPUT Boolean  FALSE    If TRUE, print summary statistics to console\n",
            "# STATS          String   ---      Location of OUTPUT matrix with summary statistics computed for\n",
            "#                                  all features (17 statistics - 14 scale, 3 categorical)\n",
            "# -------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv_7wRPFSeuJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f881099-c42e-496a-e852-2b39c5910a7f"
      },
      "source": [
        "!./bin/systemds ./scripts/algorithms/Univar-Stats.dml -nvargs X=../data/haberman.data TYPES=../data/types.csv STATS=../data/univarOut.mtx CONSOLE_OUTPUT=TRUE"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###############################################################################\n",
            "#  SYSTEMDS_ROOT= .\n",
            "#  SYSTEMDS_JAR_FILE= target/SystemDS.jar\n",
            "#  CONFIG_FILE= \n",
            "#  LOG4JPROP= -Dlog4j.configuration=file:conf/log4j-silent.properties\n",
            "#  CLASSPATH= target/SystemDS.jar:./lib/*:./target/lib/*\n",
            "#  HADOOP_HOME= /content/systemds/target/hadoop-test/org/apache/hadoop\n",
            "#\n",
            "#  Running script ./scripts/algorithms/Univar-Stats.dml locally with opts: -nvargs X=../data/haberman.data TYPES=../data/types.csv STATS=../data/univarOut.mtx CONSOLE_OUTPUT=TRUE\n",
            "###############################################################################\n",
            "Executing command:     java       -Xmx4g      -Xms4g      -Xmn400m   -cp target/SystemDS.jar:./lib/*:./target/lib/*   -Dlog4j.configuration=file:conf/log4j-silent.properties   org.apache.sysds.api.DMLScript   -f ./scripts/algorithms/Univar-Stats.dml   -exec singlenode      -nvargs X=../data/haberman.data TYPES=../data/types.csv STATS=../data/univarOut.mtx CONSOLE_OUTPUT=TRUE\n",
            "\n",
            "20/07/24 18:55:38 INFO api.DMLScript: BEGIN DML run 07/24/2020 18:55:38\n",
            "20/07/24 18:55:38 INFO conf.DMLConfig: Using internal default configuration settings.  If you wish to customize any settings, please supply a `SystemDS-config.xml` file.\n",
            "20/07/24 18:55:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "20/07/24 18:55:39 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
            "20/07/24 18:55:39 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
            "20/07/24 18:55:39 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "20/07/24 18:55:39 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=kind, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(sqrt), name=std_dev, memest=16.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(print), name=parsertemp237, memest=96.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=mode, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=kind, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(sqrt), name=std_dev, memest=16.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(print), name=parsertemp237, memest=96.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=mode, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=kind, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(sqrt), name=std_dev, memest=16.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(print), name=parsertemp237, memest=96.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=mode, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=kind, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(sqrt), name=std_dev, memest=16.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(print), name=parsertemp237, memest=96.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=mode, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=kind, memest=60.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(sqrt), name=std_dev, memest=16.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(print), name=parsertemp237, memest=96.0).\n",
            "20/07/24 18:55:40 WARN opt.CostEstimator: Cannot get memory estimate for hop (op=u(castdts), name=mode, memest=60.0).\n",
            "-------------------------------------------------\n",
            "Feature [1]: Scale\n",
            " (01) Minimum             | 30.0\n",
            " (02) Maximum             | 83.0\n",
            " (03) Range               | 53.0\n",
            " (04) Mean                | 52.45751633986928\n",
            " (05) Variance            | 116.71458266366658\n",
            " (06) Std deviation       | 10.803452349303281\n",
            " (07) Std err of mean     | 0.6175922641866753\n",
            " (08) Coeff of variation  | 0.20594669940735139\n",
            " (09) Skewness            | 0.1450718616532357\n",
            " (10) Kurtosis            | -0.6150152487211726\n",
            " (11) Std err of skewness | 0.13934809593495995\n",
            " (12) Std err of kurtosis | 0.277810485320835\n",
            " (13) Median              | 52.0\n",
            " (14) Interquartile mean  | 52.16013071895425\n",
            "-------------------------------------------------\n",
            "Feature [2]: Scale\n",
            " (01) Minimum             | 58.0\n",
            " (02) Maximum             | 69.0\n",
            " (03) Range               | 11.0\n",
            " (04) Mean                | 62.85294117647059\n",
            " (05) Variance            | 10.558630665380907\n",
            " (06) Std deviation       | 3.2494046632238507\n",
            " (07) Std err of mean     | 0.18575610076612029\n",
            " (08) Coeff of variation  | 0.051698529971741194\n",
            " (09) Skewness            | 0.07798443581479181\n",
            " (10) Kurtosis            | -1.1324380182967442\n",
            " (11) Std err of skewness | 0.13934809593495995\n",
            " (12) Std err of kurtosis | 0.277810485320835\n",
            " (13) Median              | 63.0\n",
            " (14) Interquartile mean  | 62.80392156862745\n",
            "-------------------------------------------------\n",
            "Feature [3]: Scale\n",
            " (01) Minimum             | 0.0\n",
            " (02) Maximum             | 52.0\n",
            " (03) Range               | 52.0\n",
            " (04) Mean                | 4.026143790849673\n",
            " (05) Variance            | 51.691117539912135\n",
            " (06) Std deviation       | 7.189653506248555\n",
            " (07) Std err of mean     | 0.41100513466216837\n",
            " (08) Coeff of variation  | 1.7857418611299172\n",
            " (09) Skewness            | 2.954633471088322\n",
            " (10) Kurtosis            | 11.425776549251449\n",
            " (11) Std err of skewness | 0.13934809593495995\n",
            " (12) Std err of kurtosis | 0.277810485320835\n",
            " (13) Median              | 1.0\n",
            " (14) Interquartile mean  | 1.2483660130718954\n",
            "-------------------------------------------------\n",
            "0.0\n",
            " (15) Num of categories   | 2\n",
            " (16) Mode                | 1\n",
            " (17) Num of modes        | 1\n",
            "SystemDS Statistics:\n",
            "Total execution time:\t\t0.445 sec.\n",
            "\n",
            "20/07/24 18:55:40 INFO api.DMLScript: END DML run 07/24/2020 18:55:40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqY_ARNnavrC",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1 Let us inspect the output data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_eQg9TauPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "213e24f9-9029-4af9-ab3a-86340fd5c5cc"
      },
      "source": [
        "# output first 10 lines only.\n",
        "!sed -n 1,10p ../data/univarOut.mtx"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1 30.0\n",
            "1 2 58.0\n",
            "2 1 83.0\n",
            "2 2 69.0\n",
            "2 3 52.0\n",
            "3 1 53.0\n",
            "3 2 11.0\n",
            "3 3 52.0\n",
            "4 1 52.45751633986928\n",
            "4 2 62.85294117647059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5VCCweiDMjf",
        "colab_type": "text"
      },
      "source": [
        "#### B. Run SystemDS with Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJhL7lc1vf7",
        "colab_type": "text"
      },
      "source": [
        "#### Playground for DML scripts\n",
        "\n",
        "DML - A custom language designed for SystemDS with R-like syntax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzqeSor__U6M",
        "colab_type": "text"
      },
      "source": [
        "##### A test `dml` script to prototype algorithms\n",
        "\n",
        "Modify the code in the below cell and run to work develop data science tasks\n",
        "in a high level language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t59rTyNbOF5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62e608cb-b193-4cf2-98fc-d405da61dbc8"
      },
      "source": [
        "%%writefile ../test.dml\n",
        "\n",
        "# This code code acts as a playground for dml code\n",
        "X = rand (rows = 20, cols = 10)\n",
        "y = X %*% rand(rows = ncol(X), cols = 1)\n",
        "lm(X = X, y = y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ../test.dml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDfeuJYE1JfK",
        "colab_type": "text"
      },
      "source": [
        "Submit the `dml` script to Spark with `spark-submit`.\n",
        "More about [Spark Submit ↗](https://spark.apache.org/docs/latest/submitting-applications.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YokktyNE1Cig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "63f41d01-c574-4733-9584-730a4e700590"
      },
      "source": [
        "!$SPARK_HOME/bin/spark-submit \\\n",
        "    ./target/SystemDS.jar -f ../test.dml"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/07/24 18:44:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "log4j:WARN No appenders could be found for logger (org.apache.sysds.api.DMLScript).\n",
            "log4j:WARN Please initialize the log4j system properly.\n",
            "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
            "ANTLR Tool version 4.5.3 used for code generation does not match the current runtime version 4.7ANTLR Runtime version 4.5.3 used for parser compilation does not match the current runtime version 4.7ANTLR Tool version 4.5.3 used for code generation does not match the current runtime version 4.7ANTLR Runtime version 4.5.3 used for parser compilation does not match the current runtime version 4.7Calling the Direct Solver...\n",
            "Computing the statistics...\n",
            "AVG_TOT_Y, 2.477375013209132\n",
            "STDEV_TOT_Y, 0.46788728972902527\n",
            "AVG_RES_Y, 4.8647128436662966E-9\n",
            "STDEV_RES_Y, 4.656120422710408E-8\n",
            "DISPERSION, 1.998482027272949E-15\n",
            "R2, 0.9999999999999952\n",
            "ADJUSTED_R2, 0.9999999999999909\n",
            "R2_NOBIAS, 0.9999999999999953\n",
            "ADJUSTED_R2_NOBIAS, 0.9999999999999901\n",
            "R2_VS_0, 0.9999999999999999\n",
            "ADJUSTED_R2_VS_0, 0.9999999999999997\n",
            "SystemDS Statistics:\n",
            "Total execution time:\t\t0.107 sec.\n",
            "Number of executed Spark inst:\t0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCMkudo_-8_8",
        "colab_type": "text"
      },
      "source": [
        "##### Run a binary classification example with sample data\n",
        "\n",
        "One would notice that no other script than simple dml is used in this example completely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSLq2cZb_SUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example binary classification task with sample data.\n",
        "# !$SPARK_HOME/bin/spark-submit ./target/SystemDS.jar -f ./scripts/nn/examples/fm-binclass-dummy-data.dml"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}